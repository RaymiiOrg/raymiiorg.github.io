
    <!DOCTYPE html>
    <html lang="en">
        <head>
        <title>My First Kubernetes: k3s 'cluster' on 3 Orange Pi Zero 3's, including the dashboard, hello-node and failover - Raymii.org</title>
        <style> *, ::before, ::after {background-repeat: no-repeat;-webkit-box-sizing: border-box;box-sizing: border-box;}::before, ::after {text-decoration: inherit;vertical-align: inherit;}html {cursor: default;font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";line-height: 1.15;-moz-tab-size: 4;-o-tab-size: 4;tab-size: 4;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;word-break: break-word;}body {background-color: white;margin: 0;}h1 {font-size: 2em;margin: 0.67em 0;}hr {height: 0;overflow: visible;}main {display: block;}nav ol, nav ul {list-style: none;}pre {font-family: Roboto Mono, Menlo, Consolas, Ubuntu Monospace, Noto Mono, Oxygen Mono, Liberation Mono, monospace;font-size: 1em;}a {background-color: transparent;}abbr[title] {text-decoration: underline;-webkit-text-decoration: underline dotted;text-decoration: underline dotted;}b, strong {font-weight: bolder;}code, kbd, samp {font-family: Menlo, Consolas, Roboto Mono, Ubuntu Monospace, Noto Mono, Oxygen Mono, Liberation Mono, monospace;font-size: 1em;}small {font-size: 80%;}::-moz-selection {background-color: #b3d4fc;color: #000;text-shadow: none;}::selection {background-color: #b3d4fc;color: #000;text-shadow: none;}audio, canvas, iframe, img, svg, video {vertical-align: middle;}audio, video {display: inline-block;}audio:not([controls]) {display: none;height: 0;}img {border-style: none;}svg:not([fill]) {fill: currentColor;}svg:not(:root) {overflow: hidden;}table {border-collapse: collapse;}button, input, select, textarea {font-family: inherit;font-size: inherit;line-height: inherit;}button, input, select {margin: 0;}button {overflow: visible;text-transform: none;}button, [type="button"], [type="reset"], [type="submit"] {-webkit-appearance: button;}fieldset {padding: 0.35em 0.75em 0.625em;}input {overflow: visible;}legend {color: inherit;display: table;max-width: 100%;white-space: normal;}progress {display: inline-block;vertical-align: baseline;}select {text-transform: none;}textarea {margin: 0;overflow: auto;resize: vertical;}[type="checkbox"], [type="radio"] {padding: 0;}[type="search"] {-webkit-appearance: textfield;outline-offset: -2px;}::-webkit-inner-spin-button, ::-webkit-outer-spin-button {height: auto;}::-webkit-input-placeholder {color: inherit;opacity: 0.54;}::-webkit-search-decoration {-webkit-appearance: none;}::-webkit-file-upload-button {-webkit-appearance: button;font: inherit;}::-moz-focus-inner {border-style: none;padding: 0;}:-moz-focusring {outline: 1px dotted ButtonText;}details {display: block;}dialog {background-color: white;border: solid;color: black;display: block;height: -moz-fit-content;height: -webkit-fit-content;height: fit-content;left: 0;margin: auto;padding: 1em;position: absolute;right: 0;width: -moz-fit-content;width: -webkit-fit-content;width: fit-content;}dialog:not([open]) {display: none;}summary {display: list-item;}canvas {display: inline-block;}template {display: none;}a, area, button, input, label, select, summary, textarea, [tabindex] {-ms-touch-action: manipulation;touch-action: manipulation;}[hidden] {display: none;}[aria-busy="true"] {cursor: progress;}[aria-controls] {cursor: pointer;}[aria-disabled="true"], [disabled] {cursor: not-allowed;}[aria-hidden="false"][hidden]:not(:focus) {clip: rect(0, 0, 0, 0);display: inherit;position: absolute;}main, header, footer, article, section, aside, details, summary {margin: 0 auto;margin-bottom: 16px;width: 100%;}main {display: block;margin: 0 auto;max-width: 1000px;padding: 0 16px 16px;}footer {border-top: 1px solid rgba(0, 0, 0, 0.12);padding: 16px 0;text-align: left;}footer p {margin-bottom: 0;}hr {border: 0;border-top: 1px solid rgba(0, 0, 0, 0.12);display: block;margin-top: 16px;margin-bottom: 16px;width: 100%;-webkit-box-sizing: content-box;box-sizing: content-box;height: 0;overflow: visible;}img {height: auto;max-width: 100%;vertical-align: baseline;}@media screen and (max-width: 400px) {article, section, aside {clear: both;display: block;max-width: 100%;}img {margin-right: 16px;}}embed, iframe, video {border: 0;}body {color: rgba(0, 0, 0, 0.8);font-family: "Ubuntu", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";font-size: 16px;line-height: 1.5;}p {margin: 0;margin-bottom: 16px;}h1, h2, h3, h4, h5, h6 {color: inherit;font-family: inherit;line-height: 1.2;font-weight: 500;}h1 {font-size: 40px;margin: 20px 0 16px;}h2 {font-size: 32px;margin: 20px 0 16px;}h3 {color: #75cc00;font-size: 28px;margin: 16px 0 4px;}h4 {color: #75cc00;font-size: 24px;margin: 16px 0 4px;}h5 {color: #75cc00;font-size: 20px;margin: 16px 0 4px;}h6 {color: #75cc00;font-size: 16px;margin: 16px 0 4px;}small {color: rgba(0, 0, 0, 0.54);vertical-align: bottom;}pre {background: #f7f7f9;color: rgba(0, 0, 0, 0.8);display: block;font-family: "Roboto Mono", Menlo, Monaco, Consolas, "Courier New", monospace;font-size: 16px;margin: 16px 0;padding: 16px;white-space: pre-wrap;overflow-wrap: break-word;}code {background: #f7f7f9;color: rgba(0, 0, 0, 0.8);font-family: "Roboto Mono", Menlo, Monaco, Consolas, "Courier New", monospace;font-size: 16px;line-height: inherit;margin: 0;vertical-align: baseline;word-break: break-all;word-wrap: break-word;}a {color: #75cc00;text-decoration: none;background-color: transparent;}a:hover, a:focus {color: #0062cc;font-weight: bolder;text-decoration: underline;}dl {margin-bottom: 16px;}dd {margin-left: 40px;}ul, ol {margin-bottom: 8px;padding-left: 40px;vertical-align: baseline;}blockquote {border-left: 2px solid rgba(0, 0, 0, 0.8);font-family: Georgia, Times, "Times New Roman", serif;font-style: italic;margin: 16px 0;padding-left: 16px;}figcaption {font-family: Georgia, Times, "Times New Roman", serif;}u {text-decoration: underline;}s {text-decoration: line-through;}sup {font-size: 14px;vertical-align: super;}sub {font-size: 14px;vertical-align: sub;}mark {background: #ffeb3b;}input[type="text"], input[type="password"], input[type="email"], input[type="url"], input[type="date"], input[type="month"], input[type="time"], input[type="datetime"], input[type="datetime-local"], input[type="week"], input[type="number"], input[type="search"], input[type="tel"], select, textarea {background: #fff;background-clip: padding-box;border: 1px solid rgba(0, 0, 0, 0.12);border-radius: 4px;color: rgba(0, 0, 0, 0.8);display: block;width: 100%;padding: 8px 16px;line-height: 1.5;-webkit-transition: border-color .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;transition: border-color .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;transition: border-color .15s ease-in-out, box-shadow .15s ease-in-out;transition: border-color .15s ease-in-out, box-shadow .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";}input[type="color"] {background: #fff;border: 1px solid rgba(0, 0, 0, 0.12);border-radius: 4px;display: inline-block;vertical-align: middle;}input:not([type]) {-webkit-appearance: none;background: #fff;background-clip: padding-box;border: 1px solid rgba(0, 0, 0, 0.12);border-radius: 4px;color: rgba(0, 0, 0, 0.8);display: block;width: 100%;padding: 8px 16px;line-height: 1.5;-webkit-transition: border-color .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;transition: border-color .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;transition: border-color .15s ease-in-out, box-shadow .15s ease-in-out;transition: border-color .15s ease-in-out, box-shadow .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;text-align: left;}input[type="text"]:focus, input[type="password"]:focus, input[type="email"]:focus, input[type="url"]:focus, input[type="date"]:focus, input[type="month"]:focus, input[type="time"]:focus, input[type="datetime"]:focus, input[type="datetime-local"]:focus, input[type="week"]:focus, input[type="number"]:focus, input[type="search"]:focus, input[type="tel"]:focus, input[type="color"]:focus, select:focus, textarea:focus {background-color: #fff;border-color: #80bdff;outline: 0;-webkit-box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.25);box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.25);}input:not([type]):focus {background-color: #fff;border-color: #80bdff;outline: 0;-webkit-box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.25);box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.25);}input[type="file"]:focus, input[type="radio"]:focus, input[type="checkbox"]:focus {outline: 1px thin rgba(0, 0, 0, 0.12);}input[type="text"][disabled], input[type="password"][disabled], input[type="email"][disabled], input[type="url"][disabled], input[type="date"][disabled], input[type="month"][disabled], input[type="time"][disabled], input[type="datetime"][disabled], input[type="datetime-local"][disabled], input[type="week"][disabled], input[type="number"][disabled], input[type="search"][disabled], input[type="tel"][disabled], input[type="color"][disabled], select[disabled], textarea[disabled] {background-color: rgba(0, 0, 0, 0.12);color: rgba(0, 0, 0, 0.54);cursor: not-allowed;opacity: 1;}input:not([type])[disabled] {background-color: rgba(0, 0, 0, 0.12);color: rgba(0, 0, 0, 0.54);cursor: not-allowed;opacity: 1;}input[readonly], select[readonly], textarea[readonly] {border-color: rgba(0, 0, 0, 0.12);color: rgba(0, 0, 0, 0.54);}input:focus:invalid, textarea:focus:invalid, select:focus:invalid {border-color: #ea1c0d;color: #f44336;}input[type="file"]:focus:invalid:focus, input[type="radio"]:focus:invalid:focus, input[type="checkbox"]:focus:invalid:focus {outline-color: #f44336;}select {border: 1px solid rgba(0, 0, 0, 0.12);vertical-align: sub;}select:not([size]):not([multiple]) {height: -webkit-calc(2.25rem + 2px);height: calc(2.25rem + 2px);}select[multiple] {height: auto;}label {display: inline-block;line-height: 2;}fieldset {border: 0;margin: 0;padding: 8px 0;}legend {border-bottom: 1px solid rgba(0, 0, 0, 0.12);color: rgba(0, 0, 0, 0.8);display: block;margin-bottom: 8px;padding: 8px 0;width: 100%;}textarea {overflow: auto;resize: vertical;}input[type=checkbox], input[type=radio] {-webkit-box-sizing: border-box;box-sizing: border-box;padding: 0;display: inline;}input[type=submit], input[type=reset], input[type=button], button {background-color: #75cc00;border: #75cc00;border-radius: 4px;color: #fff;padding: 8px 16px;display: inline-block;font-weight: 400;text-align: center;white-space: nowrap;vertical-align: middle;-webkit-user-select: none;-moz-user-select: none;-ms-user-select: none;user-select: none;border: 1px solid transparent;font-size: 1rem;line-height: 1.5;-webkit-transition: color .15s ease-in-out, background-color .15s ease-in-out, border-color .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;transition: color .15s ease-in-out, background-color .15s ease-in-out, border-color .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;transition: color .15s ease-in-out, background-color .15s ease-in-out, border-color .15s ease-in-out, box-shadow .15s ease-in-out;transition: color .15s ease-in-out, background-color .15s ease-in-out, border-color .15s ease-in-out, box-shadow .15s ease-in-out, -webkit-box-shadow .15s ease-in-out;}input[type=submit]::-moz-focus-inner, input[type=reset]::-moz-focus-inner, input[type=button]::-moz-focus-inner, button::-moz-focus-inner {padding: 0;}input[type=submit]:hover, input[type=reset]:hover, input[type=button]:hover, button:hover {background-color: #0069d9;border-color: #0062cc;color: #fff;}input[type=submit]:not(:disabled):active, input[type=reset]:not(:disabled):active, input[type=button]:not(:disabled):active, button:not(:disabled):active {background-color: #0062cc;border-color: #005cbf;color: #fff;}input[type=submit]:focus, input[type=reset]:focus, input[type=button]:focus, button:focus {outline: 0;-webkit-box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.5);box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.5);}input[type=submit]:disabled, input[type=reset]:disabled, input[type=button]:disabled, button:disabled {opacity: .65;cursor: not-allowed;background-color: #75cc00;border-color: #75cc00;color: #fff;}table {border-top: 1px solid rgba(0, 0, 0, 0.12);margin-bottom: 16px;}caption {padding: 8px 0;}thead th {border: 0;border-bottom: 2px solid rgba(0, 0, 0, 0.12);text-align: left;}tr {margin-bottom: 8px;}th, td {border-bottom: 1px solid rgba(0, 0, 0, 0.12);padding: 16px;white-space: nowrap;vertical-align: inherit;}tfoot tr {text-align: left;}tfoot td {color: rgba(0, 0, 0, 0.54);font-size: 8px;font-style: italic;padding: 16px 4px;}a.skip-main {left:-999px;position:absolute;top:auto;width:1px;height:1px;overflow:hidden;z-index:-999;}a.skip-main:focus, a.skip-main:active {color: #fff;background-color:#000;left: auto;top: auto;width: 30%;height: auto;overflow:auto;margin: 10px 35%;padding:5px;border-radius: 15px;border:4px solid yellow;text-align:center;font-size:1.2em;z-index:999;}@font-face {font-family: 'Raleway';font-style: normal;font-weight: 600;src: url('/s/inc/css/raleway-v18-latin-600.eot');src: local(''), url('/s/inc/css/raleway-v18-latin-600.eot?#iefix') format('embedded-opentype'), url('/s/inc/css/raleway-v18-latin-600.woff2') format('woff2'), url('/s/inc/css/raleway-v18-latin-600.woff') format('woff'), url('/s/inc/css/raleway-v18-latin-600.ttf') format('truetype'), url('/s/inc/css/raleway-v18-latin-600.svg#Raleway') format('svg');}@font-face {font-family: 'Raleway';font-style: italic;font-weight: 400;src: url('/s/inc/css/raleway-v18-latin-italic.eot');src: local(''), url('/s/inc/css/raleway-v18-latin-italic.eot?#iefix') format('embedded-opentype'), url('/s/inc/css/raleway-v18-latin-italic.woff2') format('woff2'), url('/s/inc/css/raleway-v18-latin-italic.woff') format('woff'), url('/s/inc/css/raleway-v18-latin-italic.ttf') format('truetype'), url('/s/inc/css/raleway-v18-latin-italic.svg#Raleway') format('svg');}@font-face {font-family: 'Roboto Mono';font-style: normal;font-weight: 400;src: url('/s/inc/css/roboto-mono-v12-latin-regular.eot');src: local(''), url('/s/inc/css/roboto-mono-v12-latin-regular.eot?#iefix') format('embedded-opentype'), url('/s/inc/css/roboto-mono-v12-latin-regular.woff2') format('woff2'), url('/s/inc/css/roboto-mono-v12-latin-regular.woff') format('woff'), url('/s/inc/css/roboto-mono-v12-latin-regular.ttf') format('truetype'), url('/s/inc/css/roboto-mono-v12-latin-regular.svg#RobotoMono') format('svg');}@font-face {font-family: 'Roboto Mono';font-style: normal;font-weight: 600;src: url('/s/inc/css/roboto-mono-v12-latin-600.eot');src: local(''), url('/s/inc/css/roboto-mono-v12-latin-600.eot?#iefix') format('embedded-opentype'), url('/s/inc/css/roboto-mono-v12-latin-600.woff2') format('woff2'), url('/s/inc/css/roboto-mono-v12-latin-600.woff') format('woff'), url('/s/inc/css/roboto-mono-v12-latin-600.ttf') format('truetype'), url('/s/inc/css/roboto-mono-v12-latin-600.svg#RobotoMono') format('svg');}@font-face {font-family: 'Ubuntu';font-style: normal;font-weight: 400;src: url('/s/inc/css/ubuntu-v15-latin-regular.eot');src: local(''), url('/s/inc/css/ubuntu-v15-latin-regular.eot?#iefix') format('embedded-opentype'), url('/s/inc/css/ubuntu-v15-latin-regular.woff2') format('woff2'), url('/s/inc/css/ubuntu-v15-latin-regular.woff') format('woff'), url('/s/inc/css/ubuntu-v15-latin-regular.ttf') format('truetype'), url('/s/inc/css/ubuntu-v15-latin-regular.svg#Ubuntu') format('svg');}@font-face {font-family:'Raleway2';font-style:normal;font-weight:normal;src:url('/s/inc/css/raleway.eot');src:local('Raleway2'),local('Raleway2'),url('/s/inc/css/raleway.ttf') }.headheader {font-family:"Raleway2"!important }.headheader a {color:#000;text-decoration:none }.headheader a:hover {color:#000;text-decoration:none!important }#toc ul {list-style: none;margin: 0;padding: 0;}#toc h3 {color:black;}</style>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link type="application/opensearchdescription+xml" rel="search" href="/s/inc/opensearch.xml"/>
        <link rel="alternate" type="application/rss+xml" title="RSS Feed for Raymii.org" href="https://raymii.org/s/feed.xml" />         
    </head>
    <body>
        
        <a id="top-of-page"></a>
        <main>
        <a class="skip-main" href="#main">Skip to main content</a>
            <header>
                <h1 class="headheader">
                    <a href="https://raymii.org/s/">Raymii.org 
                        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAKCAYAAAD2Fg1xAAABgElEQVQ4jb3VP0iVYRTH8c9waXBokog7OYhTXChuF3GIi4hoiJA4REQIOTgGtoWTg6ODs0SYComIXCJEMhpKtD9guUU0ujRFS0PQ8DzC24v3Pq+3S9/pnMOP8/7Ocx6el/OziRN0JXTD+I2xhK4WdeNteGmbu8IgC3jQQlfCZ0zgINHzJabwoQP+ClHGV1zGJXwRDJ/FDJZi3MBQE10dL2K8gZFOGE3REDZyyjLunKG7KAzZHfMaXjXp+QbXYlzBfrvmSuhBNaHrxQU8zdQW8RhrOe0snuB7zA/jd6p4n9HV8QMfY/4JPzGAt7meFfS18LdXEk7uemIQuJ/Lj6PZQezFWhm3cTWnXcAj3MrU5oWh5WpzGM3UurGNZy28HSa8J7mB3Uy+4u/rl+UdrsT4Jraa6F6jP5M3MP0PHguzL9zzqmC2GRNYjXF2qDzDwgbgHp53wGMhJrEunGQ9oT3CQ+GFasWBsLVvwiv5XygJz/JOAe208POrJHST+CVspBB/AFY9Q3+QJqLxAAAAAElFTkSuQmCC" alt="Raymii.org Logo">
                    </a>
                </h1>
                <small>
                  Quis custodiet ipsos custodes?<br>
                  <a href="/s/">Home</a> | 
                  <a href="/s/static/About.html">About</a> | 
                  <a href="/s/tags/all.html">All pages</a> | 
                  <a href="/s/software/Sparkling_Network.html">Cluster Status</a> | 
                  <a href="https://raymii.org/s/feed.xml">RSS Feed</a> 
                </small><br/><p>
                <link href="/s/_pagefind/pagefind-ui.css" rel="stylesheet">
                <script src="/s/_pagefind/pagefind-ui.js" type="text/javascript"></script>
                <div id="search" style="min-width:400px;max-width:1080px;"></div>
                <script>
                    window.addEventListener('DOMContentLoaded', (event) => {
                        new PagefindUI({ element: "#search" });
                    });
                </script>
                </p>
            </header>
          
    <main data-pagefind-body><h2 class='headheader' data-pagefind-meta='title' id='main'>My First Kubernetes: k3s 'cluster' on 3 Orange Pi Zero 3's, including the dashboard, hello-node and failover</h2>
<p><small>Published: <span data-pagefind-meta='date'>28-06-2024 22:30</span> | Author: Remy van Elst | <a href="My_First_Kubernetes_k3s_cluster_on_3_Orange_Pi_Zero_3s_including_k8s_dashboard_hello-node_and_failover.txt">Text only version of this article</a>
</small></p>
<br><div id="toc">
<h3>Table of Contents</h3>
<ul>
<li>
<a href="#toc_0">Setup the first node (control plane)</a>
</li>
<li>
<a href="#toc_1">Setup the worker nodes</a>
</li>
<li>
<a href="#toc_2">Admin workstation (your desktop)</a>
</li>
<li>
<a href="#toc_3">Install Dashboard UI (via Helm)</a>
</li>
<li>
<a href="#toc_4">Access Dashboard.</a>
</li>
<li>
<a href="#toc_5">Login credentials for the dashboard</a>
</li>
<li>
<a href="#toc_6">Test Deployment</a>
</li>
<li>
<a href="#toc_7">Testing failover</a>
</li>
</ul>

</div><hr><div id="contents">
<p>I&#39;ve been working as an embedded C++ developer for over 5 years now so my sysadmin / devops skills are becoming a bit rusty. The odd bit of Ansible here and there but no new stuff. I figured it was time to expore Kubernetes, as it is what all the cool kids do these days. So I <a href="/s/tutorials/Netboot_PXE_Armbian_on_an_Orange_Pi_Zero_3_from_SPI_with_NFS_root_filesystem.html">got myself 3 new SBC&#39;s</a>, the <a href="https://web.archive.org/web/20240623200133/http://www.orangepi.org/html/hardWare/computerAndMicrocontrollers/details/Orange-Pi-Zero-3.html">Orange Pi Zero 3</a>. I&#39;ll be using these to install and setup a basic Kubernetes cluster, getting the Dashboard working, installing a Hello World app and testing how the failover works. </p>

<p class="ad"> <b>Recently I removed all Google Ads from this site due to their invasive tracking, as well as Google Analytics. Please, if you found this content useful, consider a small donation using any of the options below:</b><br><br> <a href="https://leafnode.nl">I'm developing an open source monitoring app called  Leaf Node Monitoring, for windows, linux & android. Go check it out!</a><br><br> <a href="https://github.com/sponsors/RaymiiOrg/">Consider sponsoring me on Github. It means the world to me if you show your appreciation and you'll help pay the server costs.</a><br><br> <a href="https://www.digitalocean.com/?refcode=7435ae6b8212">You can also sponsor me by getting a Digital Ocean VPS. With this referral link you'll get $200 credit for 60 days. Spend $25 after your credit expires and I'll get $25!</a><br><br> </p>

<p>Meet &quot;The Cluster&quot;:</p>

<p><img src="/s/inc/img/k8s-cluster-hardware.png" alt="orange pies"></p>

<p>&quot;The Cluster&quot; consists out of the cheapest Power over Ethernet (PoE) switch I
 could find (EUR 30 on AliExpress), 3 Power over Ethernet to USB-C splitters
 and 3  <a href="https://web.archive.org/web/20240623200133/http://www.orangepi.org/html/hardWare/computerAndMicrocontrollers/details/Orange-Pi-Zero-3.html">Orange Pi Zero 3</a>
 computers with 4 GB of RAM and Gigabit Ethernet. I went with a PoE switch to
 reduce the mess of cables and adapters, which turned out to be quite small
 and okay. I put in some M3 standoffs between the Orange Pi boards and maybe
 I&#39;ll 3D-print another enclosure to tidy up the PoE splitters in the future.
 For now, it works quite well. The boards are <a href="/s/tutorials/Netboot_PXE_Armbian_on_an_Orange_Pi_Zero_3_from_SPI_with_NFS_root_filesystem.html">booting without a Micro SD
 card</a>
 since Kubernetes is so resource intensive, it would wear those cards out
 quickly.</p>

<p>Here is the end result, 3 nodes in the Kubernetes Dashboard:</p>

<p><img src="/s/inc/img/k8s-1-3.png" alt="k8s dashboard nodes"></p>

<p>In the end I even managed to deploy Grafana &amp; Prometheus (via Helm charts):</p>

<p><img src="/s/inc/img/k8s-1-4.png" alt="grafana"></p>

<p>The <a href="https://web.archive.org/web/20240627185946/https://kubernetes.io/docs/tutorials/stateless-application/guestbook/">Guestbook application</a>
was a big issue because the guide uses container images that are not built
for <code>ARM64</code>, but I managed to deploy that by manually using other images that
were suitable for ARM64. It seemed to be working, I could post messages, but
after every refresh of the page, all messages were gone. Turned out to be a
<code>redis-slave</code> version difference, <code>redis-master</code> was running version 6.0.5
and slave was running 3.2.9, which was due to the different images for ARM64.
After fixing that with an image that runs the correct <code>redis</code> version on ARM64
all worked. Lots of <code>kubectl exec -ti redis-master-podname -- sh</code> and
debugging (<code>exec 3&lt;&gt; /dev/tcp/redis-master/6379; echo INFO &gt;&amp;3; cat &lt;&amp;3</code> due
to the lack of <code>telnet</code> or <code>netcat</code>) but that helps me learn this stuff. My
<a href="https://github.com/RaymiiOrg/k8s-guestbook-arm64">yaml files for ARM64 are on github</a> for reference.</p>

<p><img src="/s/inc/img/k8s-1-2.png" alt="guestbook"></p>

<p><img src="/s/inc/img/k8s-1-1.png" alt="kubectl get pods"></p>

<h3 id="toc_0">Setup the first node (control plane)</h3>

<p>Choose one of your cluster nodes to be the first which will not only be a
worker node but also host the control plane. You can install just one node,
because in the case of <code>k3s</code> that node will also become a worker node.</p>

<p>I run the <a href="/s/tutorials/Netboot_PXE_Armbian_on_an_Orange_Pi_Zero_3_from_SPI_with_NFS_root_filesystem.html">Orange Pi Boards without a Micro SD Card</a>,
they boot up via PXE with an NFS root file system, so I cannot use
<code>overlayfs2</code>. Therefore during installation I provide an extra parameter to
use the native shapshotter. Also some <code>etcd</code> timeouts are raised. </p>

<p>Install k3s using their installer:  </p>

<pre><code>curl -sfL https://get.k3s.io | sh -s - --snapshotter=native --etcd-arg
election-timeout=5000 --etcd-arg heartbeat-interval=1000
</code></pre>

<p>Output:</p>

<pre><code>  [INFO]  Finding release for channel stable
  [INFO]  Using v1.29.5+k3s1 as release
  [INFO]  Downloading hash https://github.com/k3s-io/k3s/releases/download/v1.29.5+k3s1/sha256sum-arm64.txt
  [INFO]  Downloading binary https://github.com/k3s-io/k3s/releases/download/v1.29.5+k3s1/k3s-arm64
  [INFO]  Verifying binary download
  [INFO]  Installing k3s to /usr/local/bin/k3s
  [INFO]  Skipping installation of SELinux RPM
  [INFO]  Creating /usr/local/bin/kubectl symlink to k3s
  [INFO]  Creating /usr/local/bin/crictl symlink to k3s
  [INFO]  Creating /usr/local/bin/ctr symlink to k3s
  [INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
  [INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
  [INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env
  [INFO]  systemd: Creating service file /etc/systemd/system/k3s.service
  [INFO]  systemd: Enabling k3s unit
  Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service - /etc/systemd/system/k3s.service.
  [INFO]  Host iptables-save/iptables-restore tools not found
  [INFO]  Host ip6tables-save/ip6tables-restore tools not found
  [INFO]  systemd: Starting k3s
</code></pre>

<p>(Remove the <code>--snapshotter=native</code> part if you are not running a root filesystem on NFS).</p>

<p>Get the token for cluster installation (adding the other nodes to the cluster):</p>

<pre><code>cat /var/lib/rancher/k3s/server/node-token
</code></pre>

<p>Output:</p>

<pre><code>K10a[...]418::server:7a8[...]8e441
</code></pre>

<p>Save that output somewhere. </p>

<p>Alsop save the configuration file for the admin workstation setup later on:</p>

<pre><code>cat /etc/rancher/k3s/k3s.yaml
</code></pre>

<p>Output:</p>

<pre><code>apiVersion: v1
clusters:
- cluster:
  certificate-authority-data: LS0[...]0K
  server: https://127.0.0.1:6443
  name: default
contexts:
- context:
  cluster: default
  user: default
  name: default
current-context: default
kind: Config
preferences: {}
users:
- name: default
  user:
  client-certificate-data: LS0[...]LS0K
  client-key-data: LS0t[...]LQo=
</code></pre>

<p>If you want to set up just one node you can continue on to the admin
workstation setup. Otherwise, repeat the next section for every other board
you want to add to the cluster.</p>

<p>You can test if the install worked with the following command:</p>

<pre><code>kubectl get nodes
</code></pre>

<p>Output should be a list of cluster nodes, currently just one:</p>

<pre><code>NAME            STATUS   ROLES                  AGE     VERSION
opz3-2-midden   Ready    control-plane,master   2d22h   v1.29.5+k3s1
</code></pre>

<h3 id="toc_1">Setup the worker nodes</h3>

<p>These steps are a bit different and must be done on the worker nodes. </p>

<p>Install <code>k3s</code> with the install script but provide the server address
(<code>K3S_URL</code>) and token you saved earlier:</p>

<pre><code>curl -sfL https://get.k3s.io | K3S_URL=&quot;https://192.0.2.60:6443&quot;
K3S_TOKEN=&quot;K10a[...]c6418::server:7a
[...]41&quot; sh -s - --snapshotter=native 
</code></pre>

<p>(Omit <code>--snapshotter=native</code>  if you are not running an NFS root filesystem). </p>

<p>Output:</p>

<pre><code>[INFO]  Finding release for channel stable
[INFO]  Using v1.29.5+k3s1 as release
[INFO]  Downloading hash https://github.com/k3s-io/k3s/releases/download/v1.29.5+k3s1/sha256sum-arm64.txt
[INFO]  Skipping binary downloaded, installed k3s matches hash
[INFO]  Skipping installation of SELinux RPM
[INFO]  Skipping /usr/local/bin/kubectl symlink to k3s, already exists
[INFO]  Skipping /usr/local/bin/crictl symlink to k3s, already exists
[INFO]  Skipping /usr/local/bin/ctr symlink to k3s, already exists
[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
[INFO]  Creating uninstall script /usr/local/bin/k3s-agent-uninstall.sh
[INFO]  env: Creating environment file /etc/systemd/system/k3s-agent.service.env
[INFO]  systemd: Creating service file /etc/systemd/system/k3s-agent.service
[INFO]  systemd: Enabling k3s-agent unit
Created symlink /etc/systemd/system/multi-user.target.wants/k3s-agent.service - /etc/systemd/system/k3s-agent.service.
[INFO]  Host iptables-save/iptables-restore tools not found
[INFO]  Host ip6tables-save/ip6tables-restore tools not found
[INFO]  systemd: Starting k3s-agent
</code></pre>

<p>Repeat the above shell command for all other nodes for this cluster.</p>

<p>You can test if the install worked with the following command on the master node:</p>

<pre><code>kubectl get nodes
</code></pre>

<p>Output should be a list of cluster nodes:</p>

<pre><code>NAME            STATUS   ROLES                  AGE     VERSION
opz3-2-midden   Ready    control-plane,master   2d22h   v1.29.5+k3s1
opz3-3-boven    Ready    &lt;none&gt;                 2d22h   v1.29.5+k3s1
opz3-1-onder    Ready    &lt;none&gt;                 2d2h    v1.29.5+k3s1
</code></pre>

<h3 id="toc_2">Admin workstation (your desktop)</h3>

<p>You should manage the cluster not on the nodes but on your workstation using
<code>kubectl</code>, the command line tool for managing Kubernetes clusters. You also
need it on your (linux) desktop to gain access to the kubernetes dashboard
later on (it forwards a port to an internal service, localhost only).</p>

<p>Install <code>kubectl</code> by <a href="https://web.archive.org/web/20240625192845/https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/">following the official guide</a>. I used their provided debian APT repository.</p>

<p>Create a folder for the configuration:</p>

<pre><code>mkdir -p ~/.kube
</code></pre>

<p>Paste contents of  <code>cat /etc/rancher/k3s/k3s.yaml</code> we saved earlier from the
control plane node into the following file:</p>

<pre><code>vim ~/.kube/config
</code></pre>

<p>Replace <code>server: https://127.0.0.1:6443</code> with the IP of your first server.</p>

<p>Change permissions of the file:</p>

<pre><code>chmod 600 ~/.kube/config
</code></pre>

<p>Test using the same command we used after installing each node:</p>

<pre><code>kubectl get nodes
</code></pre>

<p>Output:</p>

<pre><code>NAME            STATUS   ROLES                  AGE     VERSION
opz3-2-midden   Ready    control-plane,master   2d22h   v1.29.5+k3s1
opz3-3-boven    Ready    &lt;none&gt;                 2d22h   v1.29.5+k3s1
opz3-1-onder    Ready    &lt;none&gt;                 2d2h    v1.29.5+k3s1
</code></pre>

<h3 id="toc_3">Install Dashboard UI (via Helm)</h3>

<p>Execute these steps on the admin workstation. Start by installing <code>helm</code>. Helm
is what we use to install the dashboard. Use the below command or your package manager:</p>

<pre><code>curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3  | bash
</code></pre>

<p>Add the <code>kubernetes-dashboard</code> helm repository:</p>

<pre><code>helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
</code></pre>

<p>Output:</p>

<pre><code>&quot;kubernetes-dashboard&quot; has been added to your repositories
</code></pre>

<p>Install the Dashboard UI:</p>

<pre><code>helm upgrade --install kubernetes-dashboard
kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace
kubernetes-dashboard
</code></pre>

<p>Output:</p>

<pre><code>Release &quot;kubernetes-dashboard&quot; does not exist. Installing it now.
NAME: kubernetes-dashboard
LAST DEPLOYED: Sat Jun 22 22:44:26 2024
NAMESPACE: kubernetes-dashboard
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
*************************************************************************************************
*** PLEASE BE PATIENT: Kubernetes Dashboard may need a few minutes to get up and become ready ***
*************************************************************************************************

Congratulations! You have just installed Kubernetes Dashboard in your cluster.

To access Dashboard run:
  kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443

NOTE: In case port-forward command does not work, make sure that kong service name is correct.
    Check the services in Kubernetes Dashboard namespace using:
    kubectl -n kubernetes-dashboard get svc

Dashboard will be available at:
  https://localhost:8443
</code></pre>

<h3 id="toc_4">Access Dashboard.</h3>

<p>To access the dashboard you first need to create a user that can generate a token. Each time you want to access the token you must first get a token using a command and then forward the ports. Follow the <code>Login Credentials</code> section below first to create the correct user. Afterwards, to get access to the dashboard, execute these commands:</p>

<pre><code>kubectl -n kubernetes-dashboard create token admin-user

kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443
</code></pre>

<p>Kubectl will make Dashboard available at <a href="https://localhost:8443/#/login">https://localhost:8443/#/login</a></p>

<h3 id="toc_5">Login credentials for the dashboard</h3>

<p>On your workstation, create a folder for our YAML files:</p>

<pre><code>mkdir k8s
cd k8s
</code></pre>

<p>Create a file for the admin user:</p>

<pre><code>vim dashboard.admin-user.yml
</code></pre>

<p>Contents:</p>

<pre><code>apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
</code></pre>

<p>Create a file for the admin user role:</p>

<pre><code>vim dashboard.admin-user-role.yml
</code></pre>

<p>Contents:</p>

<pre><code>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
</code></pre>

<p>Execute the following command to <code>apply</code> both files:</p>

<pre><code>kubectl create -f dashboard.admin-user.yml -f dashboard.admin-user-role.yml
</code></pre>

<p>Output:</p>

<pre><code>serviceaccount/admin-user created      
clusterrolebinding.rbac.authorization.k8s.io/admin-user created
</code></pre>

<p>Try to get a token to login to the dashboard:</p>

<pre><code>kubectl -n kubernetes-dashboard create token admin-user
</code></pre>

<p>Output:</p>

<pre><code>eyJh[...]HWRw
</code></pre>

<p>Login and go to the Nodes page to see your cluster in all it&#39;s glory:</p>

<p><img src="/s/inc/img/k8s-1-5.png" alt="k8s dashboard nodes"></p>

<h3 id="toc_6">Test Deployment</h3>

<p>Create a folder for your deployment yaml files:</p>

<pre><code>mkdir k8s-test
cd k8s-test
</code></pre>

<p>Most guides just have you executing a shell command, but that&#39;s not very
reproducable nor declarative. This is an example command:</p>

<pre><code>kubectl create deployment hello-node --image=registry.k8s.io/e2e-test-images/agnhost:2.39 -- /agnhost netexec --http-port=8080
</code></pre>

<p>Output:</p>

<pre><code>deployment.apps/hello-node created
</code></pre>

<p>Lets skip this imperative part and jump right into the good stuff
(declarative, files you can put in source control). </p>

<p>Create a yaml file for our test pod:</p>

<pre><code>vim hello-node-pod.yaml
</code></pre>

<p>Contents:</p>

<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: hello-kube-pod
  labels:
  component: web
spec:
  containers:
  - name: hello-kube
    image: registry.k8s.io/e2e-test-images/agnhost:2.39
    ports:
    - containerPort: 8080
    command: [&quot;/agnhost&quot;]
  args: [&quot;netexec&quot;, &quot;--http-port=8080&quot;]
</code></pre>

<p>Feed this configuration to your cluster with the following command:</p>

<pre><code>kubectl apply -f hello-node-pod.yaml
</code></pre>

<p>Output:</p>

<pre><code>pod/hello-kube-pod created
</code></pre>

<p>Check the status of the pods:</p>

<pre><code>kubectl get pods
</code></pre>

<p>Output:</p>

<pre><code>NAME                         READY   STATUS    RESTARTS      AGE
hello-kube-pod               1/1     Running   0             11s
</code></pre>

<p>Logging from indside the Pod:</p>

<pre><code>kubectl logs  hello-kube-pod
</code></pre>

<p>Output: </p>

<pre><code>I0624 04:27:56.441749       1 log.go:195] Started HTTP server on port 8080
I0624 04:27:56.442405       1 log.go:195] Started UDP server on port  8081
</code></pre>

<p>The pod is only reachable from the internal network of the kubernetes cluster.
You need to expose the pod as a Kubernetes Service of the type
<code>LoadBalancer</code>. If you are running Kubernetes on a public provider like
Google Compute Engine, you&#39;d want to use a <code>NodePort</code> because you probably
pay more for <code>LoadBalancer</code>  than for a <code>NodePort</code>.</p>

<p>If we were doing the imperative style guide you would use the following command:</p>

<pre><code>kubectl expose deployment hello-node --type=LoadBalancer --port=8080
</code></pre>

<p>But we&#39;re not doing that. Create a Yaml file for the loadbalancer:</p>

<pre><code>vim hello-node-loadbalancer.yaml
</code></pre>

<p>Contents:</p>

<pre><code>apiVersion: v1
kind: Service
metadata:
  name: hello-kube-load-balancer-service
spec:
  type: LoadBalancer
  ports:
  - port: 8081
    targetPort: 8080
  selector:
  component: web
</code></pre>

<p>The <code>hello-node</code> pod only listens on port <code>8080</code> as we configured during the
deployment. We expose it as port <code>8081</code> on the cluster.</p>

<p>Output:</p>

<pre><code>service/hello-kube-load-balancer-service created
</code></pre>

<p>Check the status of the new Service:</p>

<pre><code>kubectl get services
</code></pre>

<p>Output:</p>

<pre><code>NAME                               TYPE           CLUSTER-IP      EXTERNAL-IP                           PORT(S)
 AGE
kubernetes                         ClusterIP      10.43.0.1       &lt;none&gt;                                443/TCP
 31h
hello-kube-load-balancer-service   LoadBalancer   10.43.21.156    192.0.2.60,192.0.2.61,192.0.2.62   8081:32745/TCP   8s
</code></pre>

<p>In my case the output shows that the <code>hello-node</code> <code>LoadBalancer</code> runs on all
three of the Orange Pi k3s nodes on port <code>8081</code>.</p>

<p>If you visit the IP+Port in your browser by default <code>agnhost</code> will echo back
the request timestamp:</p>

<pre><code>NOW: 2024-06-23 17:49:08.920400061 +0000 UTC m=+516.182935643
</code></pre>

<p>Adding the path <code>/hostname</code> will echo the servers hostname:</p>

<pre><code>hello-node-ccf4b9788-gzs26
</code></pre>

<p><strong>Do note that you can run shell commands in this container</strong> so make sure you
  do not expose it to the internet:</p>

<pre><code>http://IP:PORT/shell?cmd=uname%20-a 
</code></pre>

<p>Output:</p>

<pre><code>{&quot;output&quot;:&quot;Linux hello-node-ccf4b9788-gzs26 6.6.31-current-sunxi64 #1 SMP
Fri May 17 10:02:40 UTC 2024 aarch64 Linux\n&quot;}
</code></pre>

<h3 id="toc_7">Testing failover</h3>

<p>In the Kubernetes Dashboard under Pods you can see which node is running the pod:</p>

<p><img src="/s/inc/img/k8s-1-6.png" alt="which node runs the pod"></p>

<p>You can also use the following command to get that information:</p>

<pre><code>kubectl get pods -o wide --all-namespaces --sort-by=&quot;{.spec.nodeName}&quot;
</code></pre>

<p>Output:</p>

<pre><code>NAMESPACE              NAME                                                    READY   STATUS      RESTARTS       AGE     IP            NODE            NOMINATED NODE   READINESS GATES
kube-system            svclb-frontend-d7256f7a-h27bw                           1/1     Running     0              56m     10.42.2.134   opz3-1-onder    &lt;none&gt;           &lt;none&gt;
kube-system            svclb-prometheus-server-ext-ac974dfa-qzdnp              1/1     Running     10 (12h ago)   3d23h   10.42.2.102   opz3-1-onder    &lt;none&gt;           &lt;none&gt;
guestbook              frontend-58d8fd4874-x8qsg                               1/1     Running     0              15m     10.42.2.180   opz3-1-onder    &lt;none&gt;           &lt;none&gt;
guestbook              frontend-58d8fd4874-kpk69                               1/1     Running     0              15m     10.42.2.179   opz3-1-onder    &lt;none&gt;           &lt;none&gt;
</code></pre>

<p>In my case its the node <code>opz3-1-onder</code>. If I power that machine off, the node will first go in the <code>NotReady</code> state:</p>

<pre><code>kubectl get nodes
</code></pre>

<p>Output:</p>

<pre><code>NAME            STATUS     ROLES                  AGE   VERSION
opz3-1-onder    NotReady   &lt;none&gt;                 74m   v1.29.5+k3s1
opz3-3-boven    Ready      &lt;none&gt;                 21h   v1.29.5+k3s1
opz3-2-midden   Ready      control-plane,master   21h   v1.29.5+k3s1
</code></pre>

<p>After 5 minutes the pod will be created on another node, as seen in the events log:</p>

<pre><code>kubectl events
</code></pre>

<p>Output</p>

<pre><code>LAST SEEN             TYPE      REASON                 OBJECT                            MESSAGE
23m                   Normal    ScalingReplicaSet      Deployment/hello-node             Scaled up replica set hello-node-ccf4b9788 to 1
23m                   Normal    SuccessfulCreate       ReplicaSet/hello-node-ccf4b9788   Created pod: hello-node-ccf4b9788-gzs26
23m                   Normal    Scheduled              Pod/hello-node-ccf4b9788-gzs26    Successfully assigned default/hello-node-ccf4b9788-gzs26 to opz3-1-onder
23m                   Normal    Pulling                Pod/hello-node-ccf4b9788-gzs26    Pulling image &quot;registry.k8s.io/e2e-test-images/agnhost:2.39&quot;
23m                   Normal    Pulled                 Pod/hello-node-ccf4b9788-gzs26    Successfully pulled image &quot;registry.k8s.io/e2e-test-images/agnhost:2.39&quot; in 13.116s (13.116s including waiting)
23m                   Normal    Created                Pod/hello-node-ccf4b9788-gzs26    Created container agnhost
23m                   Normal    Started                Pod/hello-node-ccf4b9788-gzs26    Started container agnhost
18m                   Normal    EnsuringLoadBalancer   Service/hello-node                Ensuring load balancer
18m                   Normal    AppliedDaemonSet       Service/hello-node                Applied LoadBalancer DaemonSet kube-system/svclb-hello-node-b0ca2b59
18m                   Normal    UpdatedLoadBalancer    Service/hello-node                Updated LoadBalancer with new IPs: [] -&gt; [192.0.2.60]
18m                   Normal    UpdatedLoadBalancer    Service/hello-node                Updated LoadBalancer with new IPs: [192.0.2.60] -&gt; [192.0.2.60 192.0.2.62]
18m                   Normal    UpdatedLoadBalancer    Service/hello-node                Updated LoadBalancer with new IPs: [192.0.2.60 192.0.2.62] -&gt; [192.0.2.60 192.0.2.61 192.0.2.62]
7m41s (x2 over 73m)   Normal    NodeNotReady           Node/opz3-1-onder                 Node opz3-1-onder status is now: NodeNotReady
7m41s                 Warning   NodeNotReady           Pod/hello-node-ccf4b9788-gzs26    Node is not ready
7m41s                 Normal    UpdatedLoadBalancer    Service/hello-node                Updated LoadBalancer with new IPs: [192.0.2.60 192.0.2.61 192.0.2.62] -&gt; [192.0.2.61 192.0.2.62]
2m36s                 Normal    TaintManagerEviction   Pod/hello-node-ccf4b9788-gzs26    Marking for deletion Pod default/hello-node-ccf4b9788-gzs26
2m36s                 Normal    SuccessfulCreate       ReplicaSet/hello-node-ccf4b9788   Created pod: hello-node-ccf4b9788-5rwdv
2m35s                 Normal    Scheduled              Pod/hello-node-ccf4b9788-5rwdv    Successfully assigned default/hello-node-ccf4b9788-5rwdv to opz3-2-midden
2m35s                 Normal    Pulling                Pod/hello-node-ccf4b9788-5rwdv    Pulling image &quot;registry.k8s.io/e2e-test-images/agnhost:2.39&quot;
2m23s                 Normal    Pulled                 Pod/hello-node-ccf4b9788-5rwdv    Successfully pulled image &quot;registry.k8s.io/e2e-test-images/agnhost:2.39&quot; in 11.63s (11.63s including waiting)
2m23s                 Normal    Created                Pod/hello-node-ccf4b9788-5rwdv    Created container agnhost
2m23s                 Normal    Started                Pod/hello-node-ccf4b9788-5rwdv    Started container agnhost
</code></pre>

<p>The old pod is being terminated:</p>

<pre><code>kubectl get pods
</code></pre>

<p>Output:</p>

<pre><code>  NAME                         READY   STATUS        RESTARTS   AGE
  hello-node-ccf4b9788-gzs26   1/1     Terminating   0          84m
  hello-node-ccf4b9788-5rwdv   1/1     Running       0          63m
</code></pre>

<p>This will succeed once the node comes back online again.</p>

<p>Time for a bit of theory on how this all works. (<a href="https://web.archive.org/web/20240623190729/https://mgarod.medium.com/the-curious-case-of-failing-over-in-kubernetes-fcd16bc9a94d">via</a>)</p>

<p>The Kubernetes controller plane is responsible for watching the state of nodes in the cluster. There are a few configurable options at play in determining the health of nodes:</p>

<ul>
<li><code>node-monitor-period</code> (Default: 5s): The period for syncing <code>NodeStatus</code> in <code>NodeController</code>.</li>
<li><code>node-monitor-grace-period</code> (Default: 40s): Amount of time which we allow running <code>Node</code> to be unresponsive before marking it unhealthy </li>
<li><code>pod-eviction-timeout</code> (Default: 5m0s): The grace period for deleting pods on failed nodes.</li>
</ul>

<p>These options mean that every 5 seconds the node must respond to a heart beat from the master node. If the node ever fails to respond, it has 40 seconds to successfully respond. After 40 seconds, the node is marked as <code>Unknown</code>. If the node remains <code>Unknown</code> (or <code>NotReady</code>) for 5 minutes, then all pods on that node will be deleted. </p>

<p>After 5 minutes Kubernetes has successfully quarantined the node and triggered a delete of all pods on the node. Those pods will then get rescheduled for deployment on a working node.</p>

<p>This is different for Stateful Sets but I&#39;ll save those for another day.</p>
Tags: <a href="../tags/armbian.html">armbian</a>
, <a href="../tags/cloud.html">cloud</a>
, <a href="../tags/helm.html">helm</a>
, <a href="../tags/k3s.html">k3s</a>
, <a href="../tags/k8s.html">k8s</a>
, <a href="../tags/kubernetes.html">kubernetes</a>
, <a href="../tags/linux.html">linux</a>
, <a href="../tags/orange-pi.html">orange-pi</a>
, <a href="../tags/raspberry-pi.html">raspberry-pi</a>
, <a href="../tags/tutorials.html">tutorials</a>
</div></main>
<br/>
<footer>
<br>
                <p><small>
                <a href="/s/">Home</a> | 
                <a href="/s/static/About.html">About</a> | 
                <a href="/s/tags/all.html">All pages</a> | 
                <a href="/s/software/Sparkling_Network.html">Cluster Status</a> | 
                Generated by <a href="/s/software/ingsoc.html">ingsoc</a>.</small>
                </p>
    
    </footer>
    <script data-goatcounter="https://raymii.goatcounter.com/count"
            async src="//gc.zgo.at/count.js"></script>

    <script defer src="/s/inc/js/instant.5.2.0.js"  type="module" ></script>

     
    </main>
    </body>
    </html>
    