<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
    <?xml-stylesheet href="/s/inc/rss.xsl" type="text/xsl"?>
    <rss version="2.0"  xmlns:atom="http://www.w3.org/2005/Atom">
        <channel>
            <title>RSS feed for tag curl on Raymii.org</title> 
            <link>https://raymii.org/s/tags/curl.xml</link> 
            <description>RSS feed for tag curl on Raymii.org</description>
            <atom:link href="https://raymii.org/s/tags/curl.xml" rel="self" type="application/rss+xml" />
    
            <item>
                <title>Bash HTTP monitoring dashboard</title> 
                <link>https://raymii.org/s/software/Bash_HTTP_Monitoring_Dashboard.html?utm_medium=rss&amp;utm_source=raymii&amp;utm_campaign=tagrss</link> 
                <guid>https://raymii.org/s/software/Bash_HTTP_Monitoring_Dashboard.html</guid>
                <description>This is a shell script that creates a webpage with the status of HTTP(s) sites. Parallel checking, thus very fast, only dependencies are curl and bash (version 4 or above). For all of you who want a simple script with a nice webpage to check a few websites. Perfect for a wall mounted monitoring display and a Raspberry Pi. Installation and configuration is easy to do inside the script. It scales well, both on the checking side as the information display page (dense on purpose). Failed checks appear right on top for you to act on. I had this script running at home for at least a year in that form, when I showed it to a friend he liked it,  asked me to make it public, but before I did that I polished it up a bit. </description> 
                <pubDate>Sun, 27 Dec 2020 00:00:00 GMT</pubDate>
                <lastBuildDate>Mon, 11 Jan 2021 00:00:00 GMT</lastBuildDate>
            </item>
    
            <item>
                <title>Get all SSH public keys from gitlab</title> 
                <link>https://raymii.org/s/snippets/Get_all_SSH_public_keys_from_gitlab.html?utm_medium=rss&amp;utm_source=raymii&amp;utm_campaign=tagrss</link> 
                <guid>https://raymii.org/s/snippets/Get_all_SSH_public_keys_from_gitlab.html</guid>
                <description>This small snippet gets all the SSH keys from a gitlab instance. You need to be an administrator, then you can query all keys at once using the API. On the web frontend you can only see the keys per user, not all at once in an overview.</description> 
                <pubDate>Wed, 26 Aug 2020 00:00:00 GMT</pubDate>
                <lastBuildDate>Wed, 26 Aug 2020 00:00:00 GMT</lastBuildDate>
            </item>
    
            <item>
                <title>Get a JSON value with bash and sed</title> 
                <link>https://raymii.org/s/snippets/Get_json_value_with_sed.html?utm_medium=rss&amp;utm_source=raymii&amp;utm_campaign=tagrss</link> 
                <guid>https://raymii.org/s/snippets/Get_json_value_with_sed.html</guid>
                <description>Recently I was asked to get one value from a json object using only shell tools. The json in question is from a dutch radio station and it lists the current song that is played. Using this together with a few shell commands and notify-send we can show the current song when it changes as a desktop notification. I'd rather use Python or jq if it has to be shell. In this case the co-worker asked to just use simple shell tools and no external dependencies.</description> 
                <pubDate>Tue, 26 Feb 2019 00:00:00 GMT</pubDate>
                <lastBuildDate>Tue, 26 Feb 2019 00:00:00 GMT</lastBuildDate>
            </item>
    
            <item>
                <title>Check HTTP status code for a page on all DNS records</title> 
                <link>https://raymii.org/s/snippets/Check_HTTP_status_code_for_a_page_on_all_DNS_records.html?utm_medium=rss&amp;utm_source=raymii&amp;utm_campaign=tagrss</link> 
                <guid>https://raymii.org/s/snippets/Check_HTTP_status_code_for_a_page_on_all_DNS_records.html</guid>
                <description>This is a small snippet using curl to check the status code of a given URL on all DNS records for a given domain. This site has a few A records in round robin mode, and sometimes the automatic deployment fails. Using this query I can check which server is the culprit and fix it manually.</description> 
                <pubDate>Sun, 09 Apr 2017 00:00:00 GMT</pubDate>
                <lastBuildDate>Sun, 09 Apr 2017 00:00:00 GMT</lastBuildDate>
            </item>
    
            <item>
                <title>HP ILO - Quickly gather ILO version and firmware information via CURL</title> 
                <link>https://raymii.org/s/snippets/HP-ILO-Quickly-gather-firmware-and-version-information-with-CUR.html?utm_medium=rss&amp;utm_source=raymii&amp;utm_campaign=tagrss</link> 
                <guid>https://raymii.org/s/snippets/HP-ILO-Quickly-gather-firmware-and-version-information-with-CUR.html</guid>
                <description>Have a lot of HP servers with ILO cards, and want to gather information from them quicly? By default you can get some information in XML format, for ILO, ILO2, ILO3 and ILO4, with curl.</description> 
                <pubDate>Sat, 13 Apr 2013 00:00:00 GMT</pubDate>
                <lastBuildDate>Sat, 13 Apr 2013 00:00:00 GMT</lastBuildDate>
            </item>
    
        </channel>
    </rss>
    
    